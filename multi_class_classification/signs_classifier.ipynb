{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signs-pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZozSBxlr9qM"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import  DataLoader, Dataset\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxY5MjmqhWUT"
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1vMibx1ox6t"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.num_channels, 3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.num_channels*4*8*8, self.num_channels*4)\n",
        "        self.fc2 = nn.Linear(self.num_channels*4, 6)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Empieza 3x64x64\n",
        "        nn.ReLU\n",
        "        x = self.conv1(x) # num_channels x 64 x 64\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels x 32 x 32\n",
        "        x = self.conv2(x) # num_channels*2 x 32 x 32\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels*2 x 16 x 16\n",
        "        x = self.conv3(x) # num_channels*4 x 16 x 16\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels*4 x 8 x 8\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, self.num_channels*4*8*8)\n",
        "\n",
        "        # fc\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # log_softmax\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-WvhTinLocB"
      },
      "source": [
        "class SIGNSDataset(Dataset):\n",
        "    def __init__(self, base_dir, split='train', transform=None):\n",
        "        path = os.path.join(base_dir, '{}_signs'.format(split))\n",
        "        files = os.listdir(path)\n",
        "\n",
        "        self.filenames = [os.path.join(path,f) for f in files if f.endswith('.jpg')]\n",
        "        self.targets = [int(f.split('/')[-1][0]) for f in self.filenames]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.filenames[idx])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, self.targets[idx]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BusmasAU_ps"
      },
      "source": [
        "base_dir = 'data/processed/64x64_SIGNS'\n",
        "\n",
        "trainset = SIGNSDataset(base_dir, split='train', transform=transforms.ToTensor())\n",
        "dataloader = DataLoader(trainset, batch_size=32)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FIzoI3LWuFC"
      },
      "source": [
        "net = Net(32).to(device)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag-LQBi2XSVR"
      },
      "source": [
        "class RunningMetric():\n",
        "    def __init__(self):\n",
        "        self.S = 0\n",
        "        self.N = 0\n",
        "\n",
        "    def update(self, val, size):\n",
        "        self.S += val\n",
        "        self.N += size\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.S / float(self.N)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tiiSi0aa9UD"
      },
      "source": [
        "num_epoch = 100"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiJ5Uk3ibLGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed734184-cdfc-49a9-889c-1d24fec47605"
      },
      "source": [
        "for epoch in range(num_epoch):\n",
        "    print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
        "    print('(', end='')\n",
        "\n",
        "    running_loss = RunningMetric()\n",
        "    running_acc = RunningMetric()\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward() # Calculo de gradientes automaticamente\n",
        "        optimizer.step() # Actualizacion de parametros\n",
        "\n",
        "        batch_size = inputs.size()[0]\n",
        "\n",
        "        running_loss.update(loss.item()*batch_size, batch_size)\n",
        "        running_acc.update(torch.sum(preds == targets).float(), batch_size)\n",
        "        print('=', end='')\n",
        "\n",
        "    print(\")Loss: {:.4f} Acc: {:.4f}\".format(running_loss(), running_acc()) )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "(===========================)Loss: 1.7941 Acc: 0.1632\n",
            "Epoch 2/100\n",
            "(===========================)Loss: 1.7913 Acc: 0.1898\n",
            "Epoch 3/100\n",
            "(===========================)Loss: 1.7899 Acc: 0.2106\n",
            "Epoch 4/100\n",
            "(===========================)Loss: 1.7889 Acc: 0.2176\n",
            "Epoch 5/100\n",
            "(===========================)Loss: 1.7879 Acc: 0.2245\n",
            "Epoch 6/100\n",
            "(===========================)Loss: 1.7869 Acc: 0.2188\n",
            "Epoch 7/100\n",
            "(===========================)Loss: 1.7858 Acc: 0.2188\n",
            "Epoch 8/100\n",
            "(===========================)Loss: 1.7845 Acc: 0.2188\n",
            "Epoch 9/100\n",
            "(===========================)Loss: 1.7831 Acc: 0.2257\n",
            "Epoch 10/100\n",
            "(===========================)Loss: 1.7815 Acc: 0.2269\n",
            "Epoch 11/100\n",
            "(===========================)Loss: 1.7797 Acc: 0.2419\n",
            "Epoch 12/100\n",
            "(===========================)Loss: 1.7776 Acc: 0.2627\n",
            "Epoch 13/100\n",
            "(===========================)Loss: 1.7751 Acc: 0.2824\n",
            "Epoch 14/100\n",
            "(===========================)Loss: 1.7720 Acc: 0.3009\n",
            "Epoch 15/100\n",
            "(===========================)Loss: 1.7683 Acc: 0.3125\n",
            "Epoch 16/100\n",
            "(===========================)Loss: 1.7637 Acc: 0.3090\n",
            "Epoch 17/100\n",
            "(===========================)Loss: 1.7580 Acc: 0.3044\n",
            "Epoch 18/100\n",
            "(===========================)Loss: 1.7507 Acc: 0.2870\n",
            "Epoch 19/100\n",
            "(===========================)Loss: 1.7415 Acc: 0.2778\n",
            "Epoch 20/100\n",
            "(===========================)Loss: 1.7299 Acc: 0.2720\n",
            "Epoch 21/100\n",
            "(===========================)Loss: 1.7158 Acc: 0.2604\n",
            "Epoch 22/100\n",
            "(===========================)Loss: 1.6982 Acc: 0.2755\n",
            "Epoch 23/100\n",
            "(===========================)Loss: 1.6730 Acc: 0.3009\n",
            "Epoch 24/100\n",
            "(===========================)Loss: 1.6438 Acc: 0.3125\n",
            "Epoch 25/100\n",
            "(===========================)Loss: 1.6041 Acc: 0.3287\n",
            "Epoch 26/100\n",
            "(===========================)Loss: 1.5555 Acc: 0.3646\n",
            "Epoch 27/100\n",
            "(===========================)Loss: 1.4891 Acc: 0.4074\n",
            "Epoch 28/100\n",
            "(===========================)Loss: 1.4325 Acc: 0.4190\n",
            "Epoch 29/100\n",
            "(===========================)Loss: 1.3757 Acc: 0.4572\n",
            "Epoch 30/100\n",
            "(===========================)Loss: 1.2988 Acc: 0.4850\n",
            "Epoch 31/100\n",
            "(===========================)Loss: 1.2384 Acc: 0.4977\n",
            "Epoch 32/100\n",
            "(===========================)Loss: 1.2171 Acc: 0.4954\n",
            "Epoch 33/100\n",
            "(===========================)Loss: 1.1726 Acc: 0.5174\n",
            "Epoch 34/100\n",
            "(===========================)Loss: 1.1215 Acc: 0.5394\n",
            "Epoch 35/100\n",
            "(===========================)Loss: 1.0809 Acc: 0.5613\n",
            "Epoch 36/100\n",
            "(===========================)Loss: 1.0496 Acc: 0.5625\n",
            "Epoch 37/100\n",
            "(===========================)Loss: 1.0250 Acc: 0.5683\n",
            "Epoch 38/100\n",
            "(===========================)Loss: 1.0144 Acc: 0.5671\n",
            "Epoch 39/100\n",
            "(===========================)Loss: 0.9906 Acc: 0.5833\n",
            "Epoch 40/100\n",
            "(===========================)Loss: 0.9238 Acc: 0.6123\n",
            "Epoch 41/100\n",
            "(===========================)Loss: 0.8703 Acc: 0.6343\n",
            "Epoch 42/100\n",
            "(===========================)Loss: 0.8533 Acc: 0.6389\n",
            "Epoch 43/100\n",
            "(===========================)Loss: 0.8148 Acc: 0.6597\n",
            "Epoch 44/100\n",
            "(===========================)Loss: 0.7947 Acc: 0.6678\n",
            "Epoch 45/100\n",
            "(===========================)Loss: 0.7663 Acc: 0.6829\n",
            "Epoch 46/100\n",
            "(===========================)Loss: 0.7457 Acc: 0.6968\n",
            "Epoch 47/100\n",
            "(===========================)Loss: 0.7220 Acc: 0.7106\n",
            "Epoch 48/100\n",
            "(===========================)Loss: 0.7037 Acc: 0.7211\n",
            "Epoch 49/100\n",
            "(===========================)Loss: 0.6835 Acc: 0.7303\n",
            "Epoch 50/100\n",
            "(===========================)Loss: 0.6632 Acc: 0.7407\n",
            "Epoch 51/100\n",
            "(===========================)Loss: 0.6368 Acc: 0.7535\n",
            "Epoch 52/100\n",
            "(===========================)Loss: 0.6053 Acc: 0.7755\n",
            "Epoch 53/100\n",
            "(===========================)Loss: 0.5789 Acc: 0.7928\n",
            "Epoch 54/100\n",
            "(===========================)Loss: 0.5483 Acc: 0.8125\n",
            "Epoch 55/100\n",
            "(===========================)Loss: 0.5240 Acc: 0.8241\n",
            "Epoch 56/100\n",
            "(===========================)Loss: 0.4983 Acc: 0.8333\n",
            "Epoch 57/100\n",
            "(===========================)Loss: 0.4772 Acc: 0.8438\n",
            "Epoch 58/100\n",
            "(===========================)Loss: 0.4524 Acc: 0.8519\n",
            "Epoch 59/100\n",
            "(===========================)Loss: 0.4385 Acc: 0.8553\n",
            "Epoch 60/100\n",
            "(===========================)Loss: 0.4144 Acc: 0.8600\n",
            "Epoch 61/100\n",
            "(===========================)Loss: 0.4069 Acc: 0.8646\n",
            "Epoch 62/100\n",
            "(===========================)Loss: 0.3817 Acc: 0.8681\n",
            "Epoch 63/100\n",
            "(===========================)Loss: 0.3664 Acc: 0.8727\n",
            "Epoch 64/100\n",
            "(===========================)Loss: 0.3389 Acc: 0.8877\n",
            "Epoch 65/100\n",
            "(===========================)Loss: 0.3292 Acc: 0.8935\n",
            "Epoch 66/100\n",
            "(===========================)Loss: 0.2997 Acc: 0.9062\n",
            "Epoch 67/100\n",
            "(===========================)Loss: 0.2880 Acc: 0.9062\n",
            "Epoch 68/100\n",
            "(===========================)Loss: 0.2749 Acc: 0.9190\n",
            "Epoch 69/100\n",
            "(===========================)Loss: 0.2595 Acc: 0.9213\n",
            "Epoch 70/100\n",
            "(===========================)Loss: 0.2432 Acc: 0.9236\n",
            "Epoch 71/100\n",
            "(===========================)Loss: 0.2330 Acc: 0.9352\n",
            "Epoch 72/100\n",
            "(===========================)Loss: 0.2255 Acc: 0.9282\n",
            "Epoch 73/100\n",
            "(===========================)Loss: 0.2170 Acc: 0.9340\n",
            "Epoch 74/100\n",
            "(===========================)Loss: 0.2099 Acc: 0.9329\n",
            "Epoch 75/100\n",
            "(===========================)Loss: 0.2032 Acc: 0.9363\n",
            "Epoch 76/100\n",
            "(===========================)Loss: 0.2005 Acc: 0.9340\n",
            "Epoch 77/100\n",
            "(===========================)Loss: 0.1922 Acc: 0.9387\n",
            "Epoch 78/100\n",
            "(===========================)Loss: 0.1862 Acc: 0.9387\n",
            "Epoch 79/100\n",
            "(===========================)Loss: 0.1841 Acc: 0.9363\n",
            "Epoch 80/100\n",
            "(===========================)Loss: 0.1852 Acc: 0.9317\n",
            "Epoch 81/100\n",
            "(===========================)Loss: 0.1879 Acc: 0.9340\n",
            "Epoch 82/100\n",
            "(===========================)Loss: 0.1780 Acc: 0.9410\n",
            "Epoch 83/100\n",
            "(===========================)Loss: 0.1589 Acc: 0.9514\n",
            "Epoch 84/100\n",
            "(===========================)Loss: 0.1448 Acc: 0.9560\n",
            "Epoch 85/100\n",
            "(===========================)Loss: 0.1321 Acc: 0.9549\n",
            "Epoch 86/100\n",
            "(===========================)Loss: 0.1258 Acc: 0.9641\n",
            "Epoch 87/100\n",
            "(===========================)Loss: 0.1198 Acc: 0.9630\n",
            "Epoch 88/100\n",
            "(===========================)Loss: 0.1162 Acc: 0.9699\n",
            "Epoch 89/100\n",
            "(===========================)Loss: 0.1092 Acc: 0.9722\n",
            "Epoch 90/100\n",
            "(===========================)Loss: 0.1022 Acc: 0.9780\n",
            "Epoch 91/100\n",
            "(===========================)Loss: 0.1018 Acc: 0.9745\n",
            "Epoch 92/100\n",
            "(===========================)Loss: 0.0964 Acc: 0.9780\n",
            "Epoch 93/100\n",
            "(===========================)Loss: 0.0941 Acc: 0.9815\n",
            "Epoch 94/100\n",
            "(===========================)Loss: 0.0960 Acc: 0.9838\n",
            "Epoch 95/100\n",
            "(===========================)Loss: 0.1061 Acc: 0.9722\n",
            "Epoch 96/100\n",
            "(===========================)Loss: 0.1084 Acc: 0.9688\n",
            "Epoch 97/100\n",
            "(===========================)Loss: 0.1042 Acc: 0.9676\n",
            "Epoch 98/100\n",
            "(===========================)Loss: 0.1180 Acc: 0.9606\n",
            "Epoch 99/100\n",
            "(===========================)Loss: 0.0798 Acc: 0.9745\n",
            "Epoch 100/100\n",
            "(===========================)Loss: 0.1178 Acc: 0.9630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_7Wrqxk1WN"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ7uAlzwiBF8"
      },
      "source": [
        "trainset = SIGNSDataset(base_dir, split='train', transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkqOzEYEgxAa"
      },
      "source": [
        "valset = SIGNSDataset(base_dir, split='val', transform=transform)\n",
        "valloader = DataLoader(valset, batch_size=32)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCVxSOQg8n_"
      },
      "source": [
        "testset = SIGNSDataset(base_dir, split='test', transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHMUNvH4hIrp"
      },
      "source": [
        "dataloaders = { 'train': trainloader,\n",
        "                'test': testloader,\n",
        "                'val': valloader\n",
        "                }"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNi2teMjiO9q"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.num_channels = num_channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.num_channels, 3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(self.num_channels)\n",
        "        self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n",
        "        self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.num_channels*4*8*8, self.num_channels*4)\n",
        "        self.fcbn1 = nn.BatchNorm1d(self.num_channels*4)\n",
        "        self.fc2 = nn.Linear(self.num_channels*4, 6)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Empieza 3x64x64\n",
        "        nn.ReLU\n",
        "        x = self.bn1(self.conv1(x)) # num_channels x 64 x 64\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels x 32 x 32\n",
        "        x = self.bn2(self.conv2(x)) # num_channels*2 x 32 x 32\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels*2 x 16 x 16\n",
        "        x = self.bn3(self.conv3(x)) # num_channels*4 x 16 x 16\n",
        "        x = F.relu(F.max_pool2d(x, 2)) # num_channels*4 x 8 x 8\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, self.num_channels*4*8*8)\n",
        "\n",
        "        # fc\n",
        "        x = F.relu(self.fcbn1(self.fc1(x)))\n",
        "        x = F.dropout(x, p=0.8, training=True)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # log_softmax\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9aaq_wkHiv"
      },
      "source": [
        "def train_and_evaluate(model, optimizer, loss_fn, dataloaders, device, num_epoch=10, lr=0.001):\n",
        "    for g in optimizer.param_groups:\n",
        "        g['lr'] = lr\n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epoch))\n",
        "        print('(', end='')\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = RunningMetric()\n",
        "            running_acc = RunningMetric()\n",
        "\n",
        "            for inputs, targets in dataloaders[phase]:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    loss = loss_fn(outputs, targets)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() # Calculo de gradientes automaticamente\n",
        "                        optimizer.step() # Actualizacion de parametros\n",
        "\n",
        "                batch_size = inputs.size()[0]\n",
        "\n",
        "                running_loss.update(loss.item()*batch_size, batch_size)\n",
        "                running_acc.update(torch.sum(preds == targets).float(), batch_size)\n",
        "                print('=', end='')\n",
        "\n",
        "            print(\")Loss: {:.4f} Acc: {:.4f}\".format(running_loss(), running_acc()) )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bC6Uj__oUEk",
        "outputId": "eea7f12a-609f-471f-9f3e-bc1bb72bdd92"
      },
      "source": [
        "import random\n",
        "\n",
        "lrs = [10**(-random.randint(3, 7)) for _ in range(3)]\n",
        "lrs"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.001, 1e-05, 1e-07]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQdTk3QlorAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e2e587-d9c1-49df-c1a2-521de5aa339c"
      },
      "source": [
        "for lr in lrs:\n",
        "    net = Net(32).to(device)\n",
        "\n",
        "    loss_fn = nn.NLLLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "    print(lr)\n",
        "    train_and_evaluate(net, optimizer, loss_fn, dataloaders, device, lr=lr)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001\n",
            "Epoch 1/10\n",
            "(===========================)Loss: 1.6320 Acc: 0.3542\n",
            "=======)Loss: 1.9795 Acc: 0.2778\n",
            "Epoch 2/10\n",
            "(===========================)Loss: 1.1681 Acc: 0.5856\n",
            "=======)Loss: 1.0904 Acc: 0.5880\n",
            "Epoch 3/10\n",
            "(===========================)Loss: 0.9525 Acc: 0.6632\n",
            "=======)Loss: 0.9685 Acc: 0.6389\n",
            "Epoch 4/10\n",
            "(===========================)Loss: 0.8484 Acc: 0.7164\n",
            "=======)Loss: 0.8809 Acc: 0.6944\n",
            "Epoch 5/10\n",
            "(===========================)Loss: 0.7594 Acc: 0.7616\n",
            "=======)Loss: 0.7755 Acc: 0.7500\n",
            "Epoch 6/10\n",
            "(===========================)Loss: 0.6853 Acc: 0.7986\n",
            "=======)Loss: 0.7059 Acc: 0.7593\n",
            "Epoch 7/10\n",
            "(===========================)Loss: 0.6013 Acc: 0.8252\n",
            "=======)Loss: 0.6604 Acc: 0.7778\n",
            "Epoch 8/10\n",
            "(===========================)Loss: 0.5527 Acc: 0.8519\n",
            "=======)Loss: 0.6463 Acc: 0.7963\n",
            "Epoch 9/10\n",
            "(===========================)Loss: 0.5301 Acc: 0.8495\n",
            "=======)Loss: 0.5559 Acc: 0.8380\n",
            "Epoch 10/10\n",
            "(===========================)Loss: 0.4903 Acc: 0.8507\n",
            "=======)Loss: 0.4903 Acc: 0.8426\n",
            "1e-05\n",
            "Epoch 1/10\n",
            "(===========================)Loss: 2.0786 Acc: 0.1725\n",
            "=======)Loss: 1.8936 Acc: 0.1944\n",
            "Epoch 2/10\n",
            "(===========================)Loss: 2.0241 Acc: 0.1968\n",
            "=======)Loss: 1.8757 Acc: 0.2037\n",
            "Epoch 3/10\n",
            "(===========================)Loss: 1.9573 Acc: 0.2188\n",
            "=======)Loss: 1.9106 Acc: 0.2130\n",
            "Epoch 4/10\n",
            "(===========================)Loss: 1.8200 Acc: 0.2535\n",
            "=======)Loss: 1.9196 Acc: 0.2083\n",
            "Epoch 5/10\n",
            "(===========================)Loss: 1.7797 Acc: 0.2743\n",
            "=======)Loss: 1.8352 Acc: 0.2407\n",
            "Epoch 6/10\n",
            "(===========================)Loss: 1.8004 Acc: 0.2789\n",
            "=======)Loss: 1.8037 Acc: 0.2593\n",
            "Epoch 7/10\n",
            "(===========================)Loss: 1.7633 Acc: 0.2824\n",
            "=======)Loss: 1.8408 Acc: 0.2546\n",
            "Epoch 8/10\n",
            "(===========================)Loss: 1.7111 Acc: 0.3102\n",
            "=======)Loss: 1.6596 Acc: 0.2963\n",
            "Epoch 9/10\n",
            "(===========================)Loss: 1.6644 Acc: 0.3229\n",
            "=======)Loss: 1.6725 Acc: 0.3333\n",
            "Epoch 10/10\n",
            "(===========================)Loss: 1.5958 Acc: 0.3414\n",
            "=======)Loss: 1.6233 Acc: 0.3333\n",
            "1e-07\n",
            "Epoch 1/10\n",
            "(===========================)Loss: 2.1128 Acc: 0.1725\n",
            "=======)Loss: 1.9223 Acc: 0.1806\n",
            "Epoch 2/10\n",
            "(===========================)Loss: 2.0707 Acc: 0.1852\n",
            "=======)Loss: 2.0518 Acc: 0.1806\n",
            "Epoch 3/10\n",
            "(===========================)Loss: 2.0933 Acc: 0.1574\n",
            "=======)Loss: 2.0900 Acc: 0.1806\n",
            "Epoch 4/10\n",
            "(===========================)Loss: 2.0891 Acc: 0.1539\n",
            "=======)Loss: 2.1486 Acc: 0.1528\n",
            "Epoch 5/10\n",
            "(===========================)Loss: 2.0964 Acc: 0.1655\n",
            "=======)Loss: 2.0509 Acc: 0.2037\n",
            "Epoch 6/10\n",
            "(===========================)Loss: 2.0402 Acc: 0.1968\n",
            "=======)Loss: 2.0990 Acc: 0.1574\n",
            "Epoch 7/10\n",
            "(===========================)Loss: 2.1135 Acc: 0.1690\n",
            "=======)Loss: 1.9936 Acc: 0.1759\n",
            "Epoch 8/10\n",
            "(===========================)Loss: 2.1180 Acc: 0.1470\n",
            "=======)Loss: 2.0524 Acc: 0.2176\n",
            "Epoch 9/10\n",
            "(===========================)Loss: 2.1237 Acc: 0.1667\n",
            "=======)Loss: 2.0845 Acc: 0.1944\n",
            "Epoch 10/10\n",
            "(===========================)Loss: 2.0930 Acc: 0.1725\n",
            "=======)Loss: 2.0331 Acc: 0.2315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm7dkq1gpJlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d316649-a58e-41f9-f7b7-fac82082b431"
      },
      "source": [
        "net = Net(32).to(device)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "train_and_evaluate(net, optimizer, loss_fn, dataloaders, device, lr=0.001, num_epoch=100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "(===========================)Loss: 1.6670 Acc: 0.3206\n",
            "=======)Loss: 2.1736 Acc: 0.2176\n",
            "Epoch 2/100\n",
            "(===========================)Loss: 1.1971 Acc: 0.5579\n",
            "=======)Loss: 1.2827 Acc: 0.5139\n",
            "Epoch 3/100\n",
            "(===========================)Loss: 1.0464 Acc: 0.6331\n",
            "=======)Loss: 1.0325 Acc: 0.6620\n",
            "Epoch 4/100\n",
            "(===========================)Loss: 0.9250 Acc: 0.6748\n",
            "=======)Loss: 0.8625 Acc: 0.6667\n",
            "Epoch 5/100\n",
            "(===========================)Loss: 0.7989 Acc: 0.7523\n",
            "=======)Loss: 0.7900 Acc: 0.7361\n",
            "Epoch 6/100\n",
            "(===========================)Loss: 0.7285 Acc: 0.7662\n",
            "=======)Loss: 0.7673 Acc: 0.7315\n",
            "Epoch 7/100\n",
            "(===========================)Loss: 0.6607 Acc: 0.8218\n",
            "=======)Loss: 0.7904 Acc: 0.7269\n",
            "Epoch 8/100\n",
            "(===========================)Loss: 0.6133 Acc: 0.8171\n",
            "=======)Loss: 0.6375 Acc: 0.8056\n",
            "Epoch 9/100\n",
            "(===========================)Loss: 0.5544 Acc: 0.8472\n",
            "=======)Loss: 0.7006 Acc: 0.7546\n",
            "Epoch 10/100\n",
            "(===========================)Loss: 0.5133 Acc: 0.8438\n",
            "=======)Loss: 0.5925 Acc: 0.8194\n",
            "Epoch 11/100\n",
            "(===========================)Loss: 0.4832 Acc: 0.8553\n",
            "=======)Loss: 0.5642 Acc: 0.8241\n",
            "Epoch 12/100\n",
            "(===========================)Loss: 0.4243 Acc: 0.8819\n",
            "=======)Loss: 0.4922 Acc: 0.8750\n",
            "Epoch 13/100\n",
            "(===========================)Loss: 0.3848 Acc: 0.9051\n",
            "=======)Loss: 0.5010 Acc: 0.8519\n",
            "Epoch 14/100\n",
            "(===========================)Loss: 0.3650 Acc: 0.9074\n",
            "=======)Loss: 0.4684 Acc: 0.8426\n",
            "Epoch 15/100\n",
            "(===========================)Loss: 0.3540 Acc: 0.9086\n",
            "=======)Loss: 0.4335 Acc: 0.8750\n",
            "Epoch 16/100\n",
            "(===========================)Loss: 0.3321 Acc: 0.9178\n",
            "=======)Loss: 0.5062 Acc: 0.8241\n",
            "Epoch 17/100\n",
            "(===========================)Loss: 0.3077 Acc: 0.9213\n",
            "=======)Loss: 0.4202 Acc: 0.8611\n",
            "Epoch 18/100\n",
            "(===========================)Loss: 0.3043 Acc: 0.9236\n",
            "=======)Loss: 0.4833 Acc: 0.8333\n",
            "Epoch 19/100\n",
            "(===========================)Loss: 0.2632 Acc: 0.9340\n",
            "=======)Loss: 0.4398 Acc: 0.8565\n",
            "Epoch 20/100\n",
            "(===========================)Loss: 0.2825 Acc: 0.9294\n",
            "=======)Loss: 0.4071 Acc: 0.8843\n",
            "Epoch 21/100\n",
            "(===========================)Loss: 0.2500 Acc: 0.9491\n",
            "=======)Loss: 0.4858 Acc: 0.8426\n",
            "Epoch 22/100\n",
            "(===========================)Loss: 0.2292 Acc: 0.9410\n",
            "=======)Loss: 0.3737 Acc: 0.8889\n",
            "Epoch 23/100\n",
            "(===========================)Loss: 0.1939 Acc: 0.9606\n",
            "=======)Loss: 0.3355 Acc: 0.9120\n",
            "Epoch 24/100\n",
            "(===========================)Loss: 0.2107 Acc: 0.9502\n",
            "=======)Loss: 0.3172 Acc: 0.9167\n",
            "Epoch 25/100\n",
            "(===========================)Loss: 0.1986 Acc: 0.9606\n",
            "=======)Loss: 0.3035 Acc: 0.8981\n",
            "Epoch 26/100\n",
            "(===========================)Loss: 0.1922 Acc: 0.9537\n",
            "=======)Loss: 0.4092 Acc: 0.8611\n",
            "Epoch 27/100\n",
            "(===========================)Loss: 0.1747 Acc: 0.9664\n",
            "=======)Loss: 0.3452 Acc: 0.8935\n",
            "Epoch 28/100\n",
            "(===========================)Loss: 0.1914 Acc: 0.9630\n",
            "=======)Loss: 0.3230 Acc: 0.9074\n",
            "Epoch 29/100\n",
            "(===========================)Loss: 0.1945 Acc: 0.9676\n",
            "=======)Loss: 0.2997 Acc: 0.9028\n",
            "Epoch 30/100\n",
            "(===========================)Loss: 0.1550 Acc: 0.9734\n",
            "=======)Loss: 0.2695 Acc: 0.9213\n",
            "Epoch 31/100\n",
            "(===========================)Loss: 0.1618 Acc: 0.9641\n",
            "=======)Loss: 0.2664 Acc: 0.9259\n",
            "Epoch 32/100\n",
            "(===========================)Loss: 0.1481 Acc: 0.9745\n",
            "=======)Loss: 0.2750 Acc: 0.9120\n",
            "Epoch 33/100\n",
            "(===========================)Loss: 0.1313 Acc: 0.9734\n",
            "=======)Loss: 0.2567 Acc: 0.9444\n",
            "Epoch 34/100\n",
            "(===========================)Loss: 0.1527 Acc: 0.9688\n",
            "=======)Loss: 0.2744 Acc: 0.9167\n",
            "Epoch 35/100\n",
            "(===========================)Loss: 0.1551 Acc: 0.9618\n",
            "=======)Loss: 0.2575 Acc: 0.9259\n",
            "Epoch 36/100\n",
            "(===========================)Loss: 0.1252 Acc: 0.9792\n",
            "=======)Loss: 0.2422 Acc: 0.9306\n",
            "Epoch 37/100\n",
            "(===========================)Loss: 0.1274 Acc: 0.9780\n",
            "=======)Loss: 0.2393 Acc: 0.9306\n",
            "Epoch 38/100\n",
            "(===========================)Loss: 0.1209 Acc: 0.9757\n",
            "=======)Loss: 0.2485 Acc: 0.9074\n",
            "Epoch 39/100\n",
            "(===========================)Loss: 0.1138 Acc: 0.9838\n",
            "=======)Loss: 0.4069 Acc: 0.8611\n",
            "Epoch 40/100\n",
            "(===========================)Loss: 0.1126 Acc: 0.9780\n",
            "=======)Loss: 0.2015 Acc: 0.9491\n",
            "Epoch 41/100\n",
            "(===========================)Loss: 0.1003 Acc: 0.9850\n",
            "=======)Loss: 0.2414 Acc: 0.9259\n",
            "Epoch 42/100\n",
            "(===========================)Loss: 0.1043 Acc: 0.9873\n",
            "=======)Loss: 0.2124 Acc: 0.9444\n",
            "Epoch 43/100\n",
            "(===========================)Loss: 0.0974 Acc: 0.9861\n",
            "=======)Loss: 0.2166 Acc: 0.9444\n",
            "Epoch 44/100\n",
            "(===========================)Loss: 0.1023 Acc: 0.9826\n",
            "=======)Loss: 0.2675 Acc: 0.9074\n",
            "Epoch 45/100\n",
            "(===========================)Loss: 0.0984 Acc: 0.9803\n",
            "=======)Loss: 0.2347 Acc: 0.9167\n",
            "Epoch 46/100\n",
            "(===========================)Loss: 0.0985 Acc: 0.9803\n",
            "=======)Loss: 0.2281 Acc: 0.9398\n",
            "Epoch 47/100\n",
            "(===========================)Loss: 0.0828 Acc: 0.9884\n",
            "=======)Loss: 0.3667 Acc: 0.8750\n",
            "Epoch 48/100\n",
            "(===========================)Loss: 0.0935 Acc: 0.9815\n",
            "=======)Loss: 0.1936 Acc: 0.9352\n",
            "Epoch 49/100\n",
            "(===========================)Loss: 0.0844 Acc: 0.9884\n",
            "=======)Loss: 0.1913 Acc: 0.9352\n",
            "Epoch 50/100\n",
            "(===========================)Loss: 0.0880 Acc: 0.9861\n",
            "=======)Loss: 0.1970 Acc: 0.9537\n",
            "Epoch 51/100\n",
            "(===========================)Loss: 0.0903 Acc: 0.9792\n",
            "=======)Loss: 0.2249 Acc: 0.9213\n",
            "Epoch 52/100\n",
            "(===========================)Loss: 0.0709 Acc: 0.9919\n",
            "=======)Loss: 0.1908 Acc: 0.9306\n",
            "Epoch 53/100\n",
            "(===========================)Loss: 0.0755 Acc: 0.9907\n",
            "=======)Loss: 0.1766 Acc: 0.9352\n",
            "Epoch 54/100\n",
            "(===========================)Loss: 0.0872 Acc: 0.9780\n",
            "=======)Loss: 0.2688 Acc: 0.9213\n",
            "Epoch 55/100\n",
            "(===========================)Loss: 0.0810 Acc: 0.9873\n",
            "=======)Loss: 0.1505 Acc: 0.9676\n",
            "Epoch 56/100\n",
            "(===========================)Loss: 0.0882 Acc: 0.9838\n",
            "=======)Loss: 0.1590 Acc: 0.9537\n",
            "Epoch 57/100\n",
            "(===========================)Loss: 0.0746 Acc: 0.9861\n",
            "=======)Loss: 0.1531 Acc: 0.9722\n",
            "Epoch 58/100\n",
            "(===========================)Loss: 0.0666 Acc: 0.9896\n",
            "=======)Loss: 0.1812 Acc: 0.9491\n",
            "Epoch 59/100\n",
            "(===========================)Loss: 0.0629 Acc: 0.9931\n",
            "=======)Loss: 0.1866 Acc: 0.9491\n",
            "Epoch 60/100\n",
            "(===========================)Loss: 0.0662 Acc: 0.9907\n",
            "=======)Loss: 0.2363 Acc: 0.9398\n",
            "Epoch 61/100\n",
            "(===========================)Loss: 0.0628 Acc: 0.9919\n",
            "=======)Loss: 0.1708 Acc: 0.9537\n",
            "Epoch 62/100\n",
            "(===========================)Loss: 0.0642 Acc: 0.9919\n",
            "=======)Loss: 0.1907 Acc: 0.9398\n",
            "Epoch 63/100\n",
            "(===========================)Loss: 0.0657 Acc: 0.9873\n",
            "=======)Loss: 0.1279 Acc: 0.9444\n",
            "Epoch 64/100\n",
            "(===========================)Loss: 0.0592 Acc: 0.9907\n",
            "=======)Loss: 0.2025 Acc: 0.9306\n",
            "Epoch 65/100\n",
            "(===========================)Loss: 0.0674 Acc: 0.9907\n",
            "=======)Loss: 0.1906 Acc: 0.9630\n",
            "Epoch 66/100\n",
            "(===========================)Loss: 0.0586 Acc: 0.9907\n",
            "=======)Loss: 0.1740 Acc: 0.9352\n",
            "Epoch 67/100\n",
            "(===========================)Loss: 0.0620 Acc: 0.9873\n",
            "=======)Loss: 0.1953 Acc: 0.9444\n",
            "Epoch 68/100\n",
            "(===========================)Loss: 0.0612 Acc: 0.9942\n",
            "=======)Loss: 0.1595 Acc: 0.9537\n",
            "Epoch 69/100\n",
            "(===========================)Loss: 0.0484 Acc: 0.9965\n",
            "=======)Loss: 0.2563 Acc: 0.9074\n",
            "Epoch 70/100\n",
            "(===========================)Loss: 0.0658 Acc: 0.9896\n",
            "=======)Loss: 0.1266 Acc: 0.9769\n",
            "Epoch 71/100\n",
            "(===========================)Loss: 0.0543 Acc: 0.9931\n",
            "=======)Loss: 0.1475 Acc: 0.9537\n",
            "Epoch 72/100\n",
            "(===========================)Loss: 0.0585 Acc: 0.9954\n",
            "=======)Loss: 0.1541 Acc: 0.9583\n",
            "Epoch 73/100\n",
            "(===========================)Loss: 0.0524 Acc: 0.9884\n",
            "=======)Loss: 0.1764 Acc: 0.9444\n",
            "Epoch 74/100\n",
            "(===========================)Loss: 0.0674 Acc: 0.9931\n",
            "=======)Loss: 0.1968 Acc: 0.9537\n",
            "Epoch 75/100\n",
            "(===========================)Loss: 0.0456 Acc: 0.9931\n",
            "=======)Loss: 0.1269 Acc: 0.9630\n",
            "Epoch 76/100\n",
            "(===========================)Loss: 0.0484 Acc: 0.9907\n",
            "=======)Loss: 0.1766 Acc: 0.9537\n",
            "Epoch 77/100\n",
            "(===========================)Loss: 0.0576 Acc: 0.9931\n",
            "=======)Loss: 0.1930 Acc: 0.9306\n",
            "Epoch 78/100\n",
            "(===========================)Loss: 0.0442 Acc: 0.9942\n",
            "=======)Loss: 0.1821 Acc: 0.9398\n",
            "Epoch 79/100\n",
            "(===========================)Loss: 0.0429 Acc: 0.9965\n",
            "=======)Loss: 0.1464 Acc: 0.9583\n",
            "Epoch 80/100\n",
            "(===========================)Loss: 0.0517 Acc: 0.9884\n",
            "=======)Loss: 0.1897 Acc: 0.9537\n",
            "Epoch 81/100\n",
            "(===========================)Loss: 0.0531 Acc: 0.9931\n",
            "=======)Loss: 0.2151 Acc: 0.9444\n",
            "Epoch 82/100\n",
            "(===========================)Loss: 0.0508 Acc: 0.9954\n",
            "=======)Loss: 0.1828 Acc: 0.9352\n",
            "Epoch 83/100\n",
            "(===========================)Loss: 0.0529 Acc: 0.9942\n",
            "=======)Loss: 0.1571 Acc: 0.9352\n",
            "Epoch 84/100\n",
            "(===========================)Loss: 0.0506 Acc: 0.9942\n",
            "=======)Loss: 0.1910 Acc: 0.9491\n",
            "Epoch 85/100\n",
            "(===========================)Loss: 0.0395 Acc: 0.9965\n",
            "=======)Loss: 0.1943 Acc: 0.9352\n",
            "Epoch 86/100\n",
            "(===========================)Loss: 0.0398 Acc: 0.9942\n",
            "=======)Loss: 0.1162 Acc: 0.9722\n",
            "Epoch 87/100\n",
            "(===========================)Loss: 0.0458 Acc: 0.9907\n",
            "=======)Loss: 0.1704 Acc: 0.9259\n",
            "Epoch 88/100\n",
            "(===========================)Loss: 0.0520 Acc: 0.9942\n",
            "=======)Loss: 0.1255 Acc: 0.9722\n",
            "Epoch 89/100\n",
            "(===========================)Loss: 0.0388 Acc: 0.9942\n",
            "=======)Loss: 0.0994 Acc: 0.9769\n",
            "Epoch 90/100\n",
            "(===========================)Loss: 0.0565 Acc: 0.9861\n",
            "=======)Loss: 0.1263 Acc: 0.9676\n",
            "Epoch 91/100\n",
            "(===========================)Loss: 0.0333 Acc: 0.9977\n",
            "=======)Loss: 0.1382 Acc: 0.9583\n",
            "Epoch 92/100\n",
            "(===========================)Loss: 0.0475 Acc: 0.9896\n",
            "=======)Loss: 0.1355 Acc: 0.9491\n",
            "Epoch 93/100\n",
            "(===========================)Loss: 0.0425 Acc: 0.9988\n",
            "=======)Loss: 0.1399 Acc: 0.9630\n",
            "Epoch 94/100\n",
            "(===========================)Loss: 0.0396 Acc: 0.9965\n",
            "=======)Loss: 0.1349 Acc: 0.9630\n",
            "Epoch 95/100\n",
            "(===========================)Loss: 0.0420 Acc: 0.9965\n",
            "=======)Loss: 0.1600 Acc: 0.9398\n",
            "Epoch 96/100\n",
            "(===========================)Loss: 0.0372 Acc: 0.9942\n",
            "=======)Loss: 0.1290 Acc: 0.9537\n",
            "Epoch 97/100\n",
            "(===========================)Loss: 0.0413 Acc: 0.9942\n",
            "=======)Loss: 0.1018 Acc: 0.9861\n",
            "Epoch 98/100\n",
            "(===========================)Loss: 0.0369 Acc: 0.9954\n",
            "=======)Loss: 0.1329 Acc: 0.9491\n",
            "Epoch 99/100\n",
            "(===========================)Loss: 0.0358 Acc: 0.9965\n",
            "=======)Loss: 0.1222 Acc: 0.9769\n",
            "Epoch 100/100\n",
            "(===========================)Loss: 0.0406 Acc: 0.9931\n",
            "=======)Loss: 0.1209 Acc: 0.9630\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}